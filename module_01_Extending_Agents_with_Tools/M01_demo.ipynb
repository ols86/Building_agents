{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pydantic\n",
      "  Using cached pydantic-2.12.5-py3-none-any.whl.metadata (90 kB)\n",
      "Collecting openai\n",
      "  Downloading openai-2.16.0-py3-none-any.whl.metadata (29 kB)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic)\n",
      "  Using cached annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.41.5 (from pydantic)\n",
      "  Using cached pydantic_core-2.41.5-cp314-cp314-macosx_11_0_arm64.whl.metadata (7.3 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.14.1 in /Users/oliver.j.wickens/Learning/Udacity/Module_3/venv/lib/python3.14/site-packages (from pydantic) (4.15.0)\n",
      "Collecting typing-inspection>=0.4.2 (from pydantic)\n",
      "  Using cached typing_inspection-0.4.2-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /Users/oliver.j.wickens/Learning/Udacity/Module_3/venv/lib/python3.14/site-packages (from openai) (4.12.1)\n",
      "Collecting distro<2,>=1.7.0 (from openai)\n",
      "  Using cached distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Users/oliver.j.wickens/Learning/Udacity/Module_3/venv/lib/python3.14/site-packages (from openai) (0.28.1)\n",
      "Collecting jiter<1,>=0.10.0 (from openai)\n",
      "  Using cached jiter-0.12.0-cp314-cp314-macosx_11_0_arm64.whl.metadata (5.2 kB)\n",
      "Collecting sniffio (from openai)\n",
      "  Using cached sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting tqdm>4 (from openai)\n",
      "  Using cached tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Requirement already satisfied: idna>=2.8 in /Users/oliver.j.wickens/Learning/Udacity/Module_3/venv/lib/python3.14/site-packages (from anyio<5,>=3.5.0->openai) (3.11)\n",
      "Requirement already satisfied: certifi in /Users/oliver.j.wickens/Learning/Udacity/Module_3/venv/lib/python3.14/site-packages (from httpx<1,>=0.23.0->openai) (2026.1.4)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/oliver.j.wickens/Learning/Udacity/Module_3/venv/lib/python3.14/site-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /Users/oliver.j.wickens/Learning/Udacity/Module_3/venv/lib/python3.14/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
      "Using cached pydantic-2.12.5-py3-none-any.whl (463 kB)\n",
      "Using cached pydantic_core-2.41.5-cp314-cp314-macosx_11_0_arm64.whl (1.9 MB)\n",
      "Downloading openai-2.16.0-py3-none-any.whl (1.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Using cached jiter-0.12.0-cp314-cp314-macosx_11_0_arm64.whl (318 kB)\n",
      "Using cached annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Using cached tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Using cached typing_inspection-0.4.2-py3-none-any.whl (14 kB)\n",
      "Using cached sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "Installing collected packages: typing-inspection, tqdm, sniffio, pydantic-core, jiter, distro, annotated-types, pydantic, openai\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9/9\u001b[0m [openai]2m8/9\u001b[0m [openai]c]\n",
      "\u001b[1A\u001b[2KSuccessfully installed annotated-types-0.7.0 distro-1.9.0 jiter-0.12.0 openai-2.16.0 pydantic-2.12.5 pydantic-core-2.41.5 sniffio-1.3.1 tqdm-4.67.1 typing-inspection-0.4.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install pydantic openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-dotenv in /Users/oliver.j.wickens/Learning/Udacity/Module_3/venv/lib/python3.14/site-packages (1.2.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install python-dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Tools\n",
    "This notebook demonstrates how we can use tools to gather information and provide more accurate responses. We'll build a weather-checking mock as an example.\n",
    "\n",
    "## What we'll learn:\n",
    "- Basic interaction with Language Models (LLM)\n",
    "- How to create and use tools with AI\n",
    "- The complete flow of an AI agent using tools\n",
    "- Understanding the message flow in a tool-enabled conversation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from dotenv import load_dotenv\n",
    "from lib.messages import UserMessage, SystemMessage, ToolMessage  # Different message types\n",
    "from lib.tooling import tool  # Tool decorator for creating AI tools\n",
    "from lib.llm import LLM  # Our Language Model wrapper\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OPENAI_API_KEY starts with: sk-proj-vM\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(\"OPENAI_API_KEY starts with:\", os.getenv(\"OPENAI_API_KEY\")[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_model = LLM(\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic LLM Interaction\n",
    "Before we dive into tools, let's understand how to interact with our Language Model in its simplest form. \n",
    "There are two main ways to communicate with the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Single Query Response:\n",
      " An AI agent is a system or entity that uses artificial intelligence techniques to perceive its environment, make decisions, and take actions to achieve specific goals. AI agents can operate autonomously or semi-autonomously and can be found in various applications, ranging from simple rule-based systems to complex machine learning models.\n",
      "\n",
      "Key characteristics of AI agents include:\n",
      "\n",
      "1. **Perception**: AI agents can gather information from their environment through sensors or data inputs. This could involve processing visual data, audio signals, or other forms of input.\n",
      "\n",
      "2. **Decision-Making**: Based on the information they perceive, AI agents can analyze the data and make decisions. This can involve reasoning, planning, and learning from past experiences.\n",
      "\n",
      "3. **Action**: After making decisions, AI agents can take actions to interact with their environment. This could involve physical actions (like a robot moving) or digital actions (like a software agent executing commands).\n",
      "\n",
      "4. **Autonomy**: Many AI agents operate with a degree of autonomy, meaning they can perform tasks without human intervention. However, some may require human oversight or input.\n",
      "\n",
      "5. **Adaptability**: Advanced AI agents can learn from their experiences and adapt their behavior over time, improving their performance in specific tasks.\n",
      "\n",
      "AI agents can be categorized into different types, such as:\n",
      "\n",
      "- **Reactive Agents**: These agents respond to specific stimuli in their environment without maintaining an internal state or memory.\n",
      "  \n",
      "- **Deliberative Agents**: These agents maintain an internal model of the world and can plan and reason about their actions.\n",
      "\n",
      "- **Learning Agents**: These agents can improve their performance over time by learning from data and experiences.\n",
      "\n",
      "Examples of AI agents include virtual assistants (like Siri or Alexa), autonomous vehicles, recommendation systems, and chatbots. Each of these agents uses AI techniques to perform tasks and interact with users or their environment effectively.\n"
     ]
    }
   ],
   "source": [
    "# Method 1: Simple single-turn query\n",
    "response = chat_model.invoke(\"What is an AI Agent?\")\n",
    "print(\"Single Query Response:\\n\", response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Structured Conversation Response:\n",
      " Function calling is a programming concept where a specific function (a block of code designed to perform a particular task) is executed or invoked within a program. When a function is called, the program temporarily transfers control to that function, executes its code, and then returns control back to the point where the function was called. \n",
      "\n",
      "### Key Concepts of Function Calling:\n",
      "\n",
      "1. **Function Definition**: Before a function can be called, it must be defined. This includes specifying the function's name, parameters (if any), and the code that will be executed.\n",
      "\n",
      "2. **Parameters and Arguments**: Functions can take inputs known as parameters. When calling a function, you provide arguments that correspond to these parameters.\n",
      "\n",
      "3. **Return Values**: Functions can return values to the caller. This allows the function to send back results after performing its task.\n",
      "\n",
      "4. **Scope**: Variables defined within a function are typically local to that function and cannot be accessed outside of it, unless they are returned or defined in a broader scope.\n",
      "\n",
      "5. **Recursion**: A function can call itself, which is known as recursion. This is often used for problems that can be broken down into smaller, similar problems.\n",
      "\n",
      "### Example in Python:\n",
      "\n",
      "```python\n",
      "def add(a, b):\n",
      "    return a + b\n",
      "\n",
      "# Function calling\n",
      "result = add(5, 3)\n",
      "print(result)  # Output: 8\n",
      "```\n",
      "\n",
      "In this example, the function `add` is defined to take two parameters, `a` and `b`. When we call `add(5, 3)`, it executes the code within the function and returns the sum, which is then printed.\n",
      "\n",
      "### Importance of Function Calling:\n",
      "\n",
      "- **Code Reusability**: Functions allow you to write code once and reuse it multiple times, reducing redundancy.\n",
      "- **Modularity**: Functions help in breaking down complex problems into smaller, manageable pieces.\n",
      "- **Maintainability**: Code organized into functions is easier to read, understand, and maintain.\n",
      "\n",
      "In summary, function calling is a fundamental aspect of programming that enhances code organization, reusability, and clarity.\n"
     ]
    }
   ],
   "source": [
    "# Method 2: Multi-turn conversation with specific roles\n",
    "messages = [\n",
    "    SystemMessage(content=\"You're an OpenAI API specialist\"),\n",
    "    UserMessage(content=\"What is Function Calling?\")\n",
    "]\n",
    "response = chat_model.invoke(messages)\n",
    "print(\"\\nStructured Conversation Response:\\n\", response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building an AI Tool\n",
    "Now let's make our AI more capable by giving it a tool to check the weather. \n",
    "This demonstrates how we can extend AI capabilities beyond just conversation.\n",
    "\n",
    "### Understanding the Tool Structure:\n",
    "1. We use the `@tool` decorator to mark a function as an AI tool\n",
    "2. The tool needs clear documentation and typed parameters\n",
    "3. The tool should return structured data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def get_weather(city: str):\n",
    "    \"\"\"Get the current temperature for a city.\n",
    "    \n",
    "    Args:\n",
    "        city (str): Name of the city to check weather for\n",
    "        \n",
    "    Returns:\n",
    "        dict: Contains temperature information for the requested city\n",
    "    \"\"\"\n",
    "    # In a real application, this would call a weather API\n",
    "    mock_weather = {\n",
    "        \"São Paulo\": \"28°C\",\n",
    "        \"Oslo\": \"-3°C\",\n",
    "        \"New York\": \"15°C\",\n",
    "        \"Tokyo\": \"22°C\"\n",
    "    }\n",
    "    return {\"temperature\": mock_weather.get(city, \"Unknown\")}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bind the tool to an LLM\n",
    "chat_model_with_tools = LLM(tools=[get_weather])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding the Tool Usage Flow\n",
    "Let's break down how the AI uses tools step by step:\n",
    "\n",
    "1. User asks a question about weather\n",
    "2. AI recognizes the need to use the weather tool\n",
    "3. AI makes a tool call\n",
    "4. Tool executes and returns results\n",
    "5. AI processes the tool's response\n",
    "6. AI formulates a natural language response\n",
    "\n",
    "Let's see this in action:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up our system with clear instructions\n",
    "messages = [\n",
    "    SystemMessage(\n",
    "        content=\"You are a helpful assistant that can access a tool to get current temperature \" \n",
    "                \"for cities. Use the tool whenever someone asks about the weather or temperature \" \n",
    "                \"in a specific location. Infor the user if you don't know the answer.\"\n",
    "    ),\n",
    "    UserMessage(content=\"How cold is it in Oslo?\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=None, role='assistant', tool_calls=[ChatCompletionMessageToolCall(id='call_LdCIo0S48pGvqLFwtGTtfPBL', function=Function(arguments='{\"city\":\"Oslo\"}', name='get_weather'), type='function')])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# AI decides to use the weather tool\n",
    "ai_message = chat_model_with_tools.invoke(messages)\n",
    "ai_message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content=\"You are a helpful assistant that can access a tool to get current temperature for cities. Use the tool whenever someone asks about the weather or temperature in a specific location. Infor the user if you don't know the answer.\", role='system'),\n",
       " UserMessage(content='How cold is it in Oslo?', role='user'),\n",
       " AIMessage(content=None, role='assistant', tool_calls=[ChatCompletionMessageToolCall(id='call_LdCIo0S48pGvqLFwtGTtfPBL', function=Function(arguments='{\"city\":\"Oslo\"}', name='get_weather'), type='function')])]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check messages structure\n",
    "messages.append(ai_message)\n",
    "messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'call_LdCIo0S48pGvqLFwtGTtfPBL'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tool call id will be required later when creating the ToolMessage\n",
    "tool_call_id = messages[-1].tool_calls[0].id\n",
    "tool_call_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'city': 'Oslo'}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract the arguments\n",
    "args = json.loads(messages[-1].tool_calls[0].function.arguments)\n",
    "args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'temperature': '-3°C'}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Execute the tool with the AI's requested parameters\n",
    "tool_result = get_weather(**args)\n",
    "tool_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ToolMessage(content='-3°C', role='tool', tool_call_id='call_LdCIo0S48pGvqLFwtGTtfPBL', name='get_weather')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a tool response message\n",
    "tool_message = ToolMessage(\n",
    "    content=tool_result[\"temperature\"], \n",
    "    tool_call_id=tool_call_id, \n",
    "    name=\"get_weather\"\n",
    ")\n",
    "tool_message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content=\"You are a helpful assistant that can access a tool to get current temperature for cities. Use the tool whenever someone asks about the weather or temperature in a specific location. Infor the user if you don't know the answer.\", role='system'),\n",
       " UserMessage(content='How cold is it in Oslo?', role='user'),\n",
       " AIMessage(content=None, role='assistant', tool_calls=[ChatCompletionMessageToolCall(id='call_LdCIo0S48pGvqLFwtGTtfPBL', function=Function(arguments='{\"city\":\"Oslo\"}', name='get_weather'), type='function')]),\n",
       " ToolMessage(content='-3°C', role='tool', tool_call_id='call_LdCIo0S48pGvqLFwtGTtfPBL', name='get_weather')]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check messages structure\n",
    "messages.append(tool_message)\n",
    "messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='The current temperature in Oslo is -3°C.', role='assistant', tool_calls=None)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let AI formulate final response\n",
    "ai_message = chat_model_with_tools.invoke(messages)\n",
    "ai_message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content=\"You are a helpful assistant that can access a tool to get current temperature for cities. Use the tool whenever someone asks about the weather or temperature in a specific location. Infor the user if you don't know the answer.\", role='system'),\n",
       " UserMessage(content='How cold is it in Oslo?', role='user'),\n",
       " AIMessage(content=None, role='assistant', tool_calls=[ChatCompletionMessageToolCall(id='call_LdCIo0S48pGvqLFwtGTtfPBL', function=Function(arguments='{\"city\":\"Oslo\"}', name='get_weather'), type='function')]),\n",
       " ToolMessage(content='-3°C', role='tool', tool_call_id='call_LdCIo0S48pGvqLFwtGTtfPBL', name='get_weather'),\n",
       " AIMessage(content='The current temperature in Oslo is -3°C.', role='assistant', tool_calls=None)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check messages structure\n",
    "messages.append(ai_message)\n",
    "messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "23393d2575091a37cff0d0e9e7479591a295495b26c3b2ebf9b64da572e02d85"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
